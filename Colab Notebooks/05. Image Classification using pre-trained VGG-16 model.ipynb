{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5. Image Classification using pre-trained VGG-16 model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPcH8MA7QBuNfA7g5fIbm2Y"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KeqnWrMJ7HHy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600662762757,"user_tz":-345,"elapsed":1634,"user":{"displayName":"Netra Prasad Neupane","photoUrl":"","userId":"06936625052302221360"}}},"source":["from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input,decode_predictions\n","from tensorflow.keras.preprocessing.image import load_img,img_to_array"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpdWjS4f7llQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1600662785435,"user_tz":-345,"elapsed":18544,"user":{"displayName":"Netra Prasad Neupane","photoUrl":"","userId":"06936625052302221360"}},"outputId":"81a933a7-fbdf-41eb-8161-cd892cf27d02"},"source":["# Creating an object for VGG16 pre-trained model\n","model = VGG16()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 14s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"33aBgpGh74Q8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":955},"executionInfo":{"status":"ok","timestamp":1600662891588,"user_tz":-345,"elapsed":2228,"user":{"displayName":"Netra Prasad Neupane","photoUrl":"","userId":"06936625052302221360"}},"outputId":"14b91f54-6d74-4611-a8f6-338aaf5c83c0"},"source":["model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SWjbNDiD8C-5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600662885614,"user_tz":-345,"elapsed":3007,"user":{"displayName":"Netra Prasad Neupane","photoUrl":"","userId":"06936625052302221360"}}},"source":["#Here we are taking sample images from drive  and predicting the same images on top of pre-trained VGG16 model.\n","#top=2 in decode_predictions() function means which we are taking top 2 probability values for the particular prediction. \n","\n","# for file in os.listdir('sample'):\n","#     print(file)\n","#     full_path = 'sample/' + file\n","    \n","#     image = load_img(full_path, target_size=(224, 224))\n","#     image = img_to_array(image)\n","#     image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","#     image = preprocess_input(image)\n","#     y_pred = model.predict(image)\n","#     label = decode_predictions(y_pred, top = 2)\n","#     print(label)\n","#     print()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWiXNBna8Uhc","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}